---
layout: post
title:  "Numerical Relativity 102: Simulating binary black hole collisions, quickly"
date:   2024-08-15 12:33:23 +0000
categories: C++
---

Hello! Today we're going to do one of the coolest things in all of physics in my opinion, which is simulating the collision of two black holes. Last time round, we implemented most of what we'll need to simulate this, so today's job is to capitalise on that and finally smash some black holes together

The complicated part of this article is going to be the initial conditions, which means that most of this article is actually going to be how to solve Laplacians quickly on a GPU

# Astrophysics Context

Its worth understanding for this article what we're actually trying to simulate. A black hole is an object that is so dense that light can't escape - once this happens, nothing that prevent all the matter that made up the precursor object from reaching the singularity

Eg, consider a star collapsing into a black hole. All the matter essentially shrinks to a point (or, in the case of a spinning black hole: a ring) past the event horizon, until it reaches a singularity. In pure general relativity, this singularity is (essentially^[essentially]) inevitable, and all the black holes we're dealing with today will always contain a singularity. Its also true that the singularity is - mathematically - very poorly behaved and by definition causes all the maths to explode. This makes simulating it a bit tricky. There are two approaches to handling this

[^essentially]: There's some debate around if you could construct an astrophysical black hole which has no singularity, likely containing negative energy

## Excision

A black holes interior, and exterior are causally disconnected. This means that the interior of a black hole has no effect on the wider universe, and as such - you don't actually need to simulate it. This is the excision technique for handling a black hole's interior, and involves specifying a boundary condition somewhere inside the event horizon

This also directly leads to one of my favourite papers, the turducken, where you stuff the interior with meaningless junk

## Moving punctures

This is the technique we'll actually be using, and involves a bit of trickery. In the ADM formalism, the gauge conditions define the coordinate system of what you're working with. So the trick is to make sure that the coordinates never actually meet the singularity, and it is treated as a puncture/hole in your simulation grid. This puncture is able to move around with the correct gauge conditions, and so we have a singularity that is never actually quite represented. In moving punctures, the entire simulation domain is actively simulated, unlike with excision where a portion of it is not

In practice, its a lot trickier than this, and I personally have some skepticism that that's actually what's happening. I'm going to keep the crackpot conspiracy theories to the end of this article

Notably, as the singularity represents a true discontinuity, differentiating across it is technically incorrect. This method relies on the event horizon containing errors causally

## Circular Orbits

The conventional wisdom is that black holes merge after a long inspiralling process, where the nature of gravitational wave emissions slowly circularises the orbits. This means that binary black hole orbits should be nearly perfectly circular by the time the black hole's merge

Unfortunately, this turned out not to be the case, and it appears that there is a significant amount of eccentricity (non circularity) when black holes merge. This really complicates the amount of simulating you have to do

## Unequal mass binaries

With the assumption of circular orbits, equal mass/spin binaries, and the black hole spin being aligned with the plane of the orbit, you can use octant symmetry - ie your simulation is fully symmetric and can be chopped into 8 chunks, with only one of the chunks actually being simulated

Personally I'm interested in a very general simulator which can handle anything, so we're going to avoid this octant symmetry reduction - but given its prevalence in the literature, its worth mentioning here. For equal mass binaries, this would be a flat 8x speedup, so its definitely worth investigating for lower end hardware

## Gravitational waves

The primary purpose of a black hole merger simulator is to find out what the gravitational waves look like, because LIGO (a big gravitational wave detector) can detect certain mass ranges of mergers. We're not going to be pulling out gravitational waves today, but it does mean we need to be careful to be as physical as possible

To perform this matching, as far as I know there's no better way than simply bruteforcing the entire parameter space. For a pair of black holes, you have the following parameters:

todo: no

M1: The mass of the first black hole
M2: The mass of the second black hole
S1: The spin direction - a 3-vector - of the first black hole, normalised
S2: The spin direction of the second black hole
X1: The spin constant of the first black hole
X2: The spin constant of the second black hole
e: The orbital eccentricity

This is a lot of parameters to bruteforce, and why non circular orbits are such a gigantic pain, because it adds a whole extra dimension to bruteforce

Traditional simulations in this area can take weeks to months, which you'll be glad to know is not going to be the case for us

# What's the plan?

We need a few things to get this to work:

1. A new set of initial conditions
2. New boundary conditions
3. Some modifications to the evolution equations

Of all of these, the initial conditions are by far the most complicated part, so lets get to it

# Initial conditions

I'm going to present you with the easiest set of initial conditions to implement, and we're going to really dig into it. Some discussion about alternatives and further context is given at the end of this article

The paper we're going to implement today is called [A simple construction of initial data for multiple black holes](https://arxiv.org/pdf/gr-qc/9703066). This represents an extremely traditional and widespread way to construct black hole initial conditions - its also a very good paper that you should read. There are a few things that we need to learn right off the bat

1. This doesn't actually make black holes, it makes objects that collapse into black holes. They have no event horizon, or apparent horizon
2. There is no way of a-priori specifying the mass of a black hole
3. There is a maximum value of spin that can be expressed with this technique

Lets get into it

## Implementing

To take a step back, we're trying to solve initial conditions for the following ADM variables:

$$\gamma_{ij}\\
K_{ij}\\
\alpha\\
\beta^i
$$

This technique solves for $\gamma_{ij}$ and $K_{ij}$, and leaves us to guess $\alpha$ and $\beta^i$. It falls under the class of initial conditions known as 'conformally flat'. This means it decomposes the metric tensor into a flat conformal metric (an identity matrix), and a conformal factor $\psi$. It also decomposes the extrinsic curvature $K^{ph}_{ij}$ ('physical', this is our $K_{ij}$) into a trace $K=0$, and a trace free part which this paper calls $K_{ij}$ (and other papers often call $$\bar{A}_{ij}$$). This is called a maximal slice (todo: check the _{TT} schenanigans)

The basic idea here is that with the conformally flat + trace free constraint, the momentum constraint becomes linear, allowing you to calculate the extrinsic curvature as a sum of each individual black hole's curvature, to calculate the final (conformal) curvature. The shape of the conformal factor is a *guess*, which is then corrected to be physical via a small correction $u$, by solving the laplacian (9) + (10)

## Details

This method has the following parameters:

$m_i$ bare mass parameter of each black hole
$P_i$: A 3-vector, the momentum vector of each black hole
$S_i$: A 3-vector the spin (angular momentum) of each black hole
$x_i$ the position of a black hole

I'm labelling the properties of each black hole by its index $i$, eg $P_0$ is the first black hole's momentum vector

Note that bare mass is not the same thing as mass (here: ADM mass), it only correlates to it. A black hole's spin contributes to its mass as well. On top of this, in the general case, the mass of a black hole in a binary pair is of questionable physicalness: see the end of this article for more details

I'm going to be using the notation $\bar{A}^{ij}$ to mean what this paper calls $K^{ij}$, because its simply too confusing otherwise. I'm also going to be using $\bar{\gamma}_{ij}$ to mean the conformally flat metric instead of $g_{ab}$, for the same reason

## Conformal extrinsic curvature

This is straightforward. For every black hole in our spacetime, we calculate the quantity (5), and then sum all of them. After accumulating all of these, I store $\bar{A}^{ab} \bar{A}_{ab}$ as a scalar

For a single black hole, we have this:

$$
\begin{align}
\bar{A}^{ij} &= \frac{3}{2r^2}(P^a n^b + P^b n^a - (\bar{\gamma}^{ab} - n^a n^b) P^c n_c) \\
&+ \frac{3}{r^3}(\epsilon^{acd} S_c n_d n^b + \epsilon^{bcd} S_c n_d n^a)
\end{align}
$$

Where $\epsilon$ is the levi civita symbol[^lcs]. Note that the levi civita symbol, and levi civita tensor have the same notation in the literature and are frequently freely mixed, so its not especially clear what's going on. TODO: I NEED TO CHECK THIS

[^lcs]: [see 13](https://arxiv.org/pdf/2007.14279)

$r$ is the distance in world coordinates (ie not grid coordinates) of the coordinate from the black hole in question. There's a clear problem when $r = 0$, and the solution is to either position your black holes so this is impossible, or clamp to a small value

$n$ is a normal vector, which is calculated as follows: $n^i = x^i/r$, and points away from the black hole in question

If you have no plans to ever work in non cartesian coordinate systems (which we don't), the metric tensor is the identity matrix, and you can ignore the index positions

Next up: We need the conformal factor $\psi$, which involves calculating the correction $u$

## Conformal Factor

alt https://arxiv.org/pdf/1606.04881

https://www.worldscientific.com/doi/pdf/10.1142/S2010194512004321 15? everyone uses this

The conformal factor $\psi$ here is listed as:

$$\psi = \frac{1}{\alpha} + u$$

Where $u > 1$, and $\alpha$ is:

$$\frac{1}{\alpha} = \sum^N_{i=1} \frac{m_i}{2 |\overrightarrow{r} - \overrightarrow{x}_{(i)}|}$$

Note that $r$ in the bottom term is a vector representing our current grid cell's world position. This is twice the distance of our coordinate from our $i$'th black hole

We're going to deviate a little from this definition, and instead calculate the correction as:

$$\psi = \frac{1}{\alpha} + u + 1$$

Where $u > 0$. This is because you have a lot more precision to work with for floating point near $0$ vs near $1$, so this lets us solve for much smaller corrections without needing to resort to double precision. This means our boundary condition will be slightly different ($u=0$ vs $u=1$)

### Solving for $u$

Equations (9) + (10) are a classic laplacian:

$$\begin{align}
&\Delta u + \beta(1 + \alpha u)^{-7} = 0\\
&\beta = \frac{1}{8} \alpha^7 \bar{A}^{ab}\bar{A}_{ab}
\end{align}
$$

If you're planning to implement in a more serious capacity, I'd recommend instead the form given by [this](https://arxiv.org/pdf/1606.04881) paper (18), because that's where we'll end up eventually

#### Solving laplacians in general

Our equations are of the form:

$$\Delta u = F(u)$$

And are a standard laplacian. It is common in numerical relativity to use complex solutions to solve this, and they come with caveats in terms of how to solve this. This is because solvers are CPU based, and as such need very good convergence properties to work well

Luckily, we're in GPU-land, and so the techniques are both simpler and significantly more performant

#### The boundary condition

At the edge of our grid, we need to set $u$ to something. Asymptotically, $u$ is assumed to have the form $O(\frac{1}{r})$ (todo check), and at infinity in the original definition $u ~= 1$. This means for us, $u = 0$

#### Fixed point iteration / 7 point stencil

A laplacian in flat 3d space is defined as such:

$$\Delta u = \frac{\partial^2 u}{\partial x_0 ^2} + \frac{\partial^2 u}{\partial x_1 ^2} + \frac{\partial^2 u}{\partial x_2 ^2}$$

Ie, it is the sum of second derivatives in each direction. Given a function $f(x)$, we can approximate the second derivative with finite difference coefficients:

$$\frac{\partial^2 f(x)}{\partial x^2} = \frac{f(x - h) - 2 f(x) + f(x + h)}{h^2}$$

Now, we'll treat $u$ as a function over 3d space, ie $u(x, y, z)$, and apply the above discretisation to $\Delta u$:

$$\Delta u = \frac{u(x - h, y, z) - 2 u(x, y, z) + u(x + h, y, z))}{h^2} + \frac{u(x, y - h, z) - 2 u(x, y, z) + u(x, y + h, z))}{h^2}\frac{u(x, y, z - h) - 2 u(x, y, z) + u(x, y, z + h))}{h^2}$$

Collecting all the terms, we get:

$$\frac{u(x - h, y, z) + u(x + h, y, z) + u(x, y - h, z) + u(x, y + h, z) + u(x, y, z - h) + u(x, y, z + h) - 6 u(x, y, z)}{h^2}$$

Our initial equation is $\Delta u = F(u)$, so lets substitute in, and multiply by $h^2$:

$$u(x - h, y, z) + u(x + h, y, z) + u(x, y - h, z) + u(x, y + h, z) + u(x, y, z - h) + u(x, y, z + h) - 6 u(x, y, z) = F(u) h^2$$

The iterative scheme for solving a laplacian (often called 5-point stencil in 2d, or the 7-point stencil in 3d), is given by solving for $u(x, y, z)$:

$$
u(x, y, z) = \frac{u(x - h, y, z) + u(x + h, y, z) + u(x, y - h, z) + u(x, y + h, z) + u(x, y, z - h) + u(x, y, z + h) - F(u) h^2}{6}
$$

For us, $F(u) = -\frac{1}{8} \alpha^7 \bar{A}^{ab} \bar{A}_{ab} (1 + \alpha u)^{-7}$

As a basic idea, this works, and is implementable. This is the form I used for a very long time: you just iterate the above equation until the change in $u$ is sufficiently small. There are two main issues:

1. It can be numerically unstable, particularly for spinning black holes
2. It isn't amazingly fast, it can take ~10s or so in some cases, which is still pretty fast

The first is solved by relaxation: Ie taking our old guess, and our new guess, and taking some fraction between the two: `mix(u, nextu, 0.9)`. This unfortunately reduces the speed of convergence

Luckily, performance issues are easily fixable!

#### Multigrid

The easiest way to speed up performance is with a multigrid solution. Essentially, instead of solving at your final grid resolution, you start off at a low resolution, solve for that, then progressively solve for higher resolutions starting with your low resolution guess upscaled to a higher resolution

This solution works incredibly well for this problem, as there is no high frequency content in $u$

#### Red-black

Another component that gives a free 2x performance increase is red-black iteration. Imagine the laplacian problem in 2d:

todo: picture

Each cell only accesses a adjacent grid cells:

Todo: red/black

This means that when updating, we can skip half the cells in the 'wrong' colour, and then update them next time round instead. Note that we *do* use $u$ here to calculate $F(u)$, which means that the $u$ for the laplacian's and the $u$ for our rhs are at different steps if we use red-black iteration. This does not affect convergence

The iteration scheme to use in 3d is as follows:

Todo: code

## Finishing up

After solving the laplacian, we have a value for $u$, which allows us to calculate $\psi$ directly. From here, we can calculate our ADM variables:

$$\begin{align}
\gamma_{ij} &= \psi^4 \bar{\gamma}_{ij}\\
K_{ij} &= \psi^{-2} \bar{A}_{ij}
\end{align}$$

We already know how to construct our BSSN variables, see the last article

The ADM mass can be estimated via todo. If you need a specific ADM mass, iterate. Binary search. Spin! Woo!

### Gauge

We still don't have an initial solution for our gauge variables however. Universally, $\beta^i = 0$. The lapse $\alpha$ is a tad more interesting - there are two[^twomain] main options:

1. $\alpha = 1$
2. $\alpha = \psi^{-2}$

Both work well and are widely used. The latter is better for black holes, but I've found tends to lead to neutron stars exploding spectacularly. We're going to use #2 for this article, as we're strictly dealing with black holes

[^twomain]: In general, these two options are the two simple options that work well, but there are a variety of alternatives

# Boundary conditions

https://arxiv.org/pdf/1503.03436 2.39

Our data is no longer periodic, so we need a new set of boundary conditions. The simplest good-enough boundary condition is called the Sommerfeld boundary conditions. This radiaties away your data to the asymptotic value at the boundary. This is defined as:

$$\frac{\partial f}{\partial t} = -\frac{v x_i}{\partial x_i} - v \frac{f - f_0}{r}$$

$f$ is our value for whatever field we're radiating, $x_i$ is the cell's position in world coordinates, $v$ is the wave speed, $f_0$ is the asymptotic value, and $r$ is the distance from the centre

All waves have a speed of $1$, except for the gauge variables which have a speed of $\sqrt{2}$. Todo: Cite

## Other boundary conditions

There are alternatives to sommerfeld which I will mention in passing

1. Fixing every field to its asymptotic value at the boundary, and not evolving it. This works if your boundary is far away (as spacetime is asmptotically flat), but requires a lot of extra simulation space
2. Sponge constructions. This damps outgoing waves gradually. Its easy to implement, but the sponge area must be large enough to avoid reflections, which also requires a lot of extra simulation space
3. Constraint preserving boundary conditions. These are the best and allow you to place the boundaries closest to your simulation area (as they introduce the least error), but are more complex to implement. Its on my infinitely long todo list, and there'll likely be an article on this in the future
4. Hybrid schemes. Some schemes assume that $\beta^i = 0$ on the boundary, and evolve $\tilde{\gamma}_{ij}$ freely, then use traditional boundary conditions for the other variables. I've never tested this and have no information on the quality of the result, but it seems to work
5. Compactification. This adjusts the coordinate system so that the grid represents the entire computational domain, and you have no boundary. This is nice theoretically, but in practice seems to be similar to a sponge construction

As a general note, its very common to assume that the speed of the gauge waves is $1$, instead of $\sqrt{2}$

# Modifying the equations

We've now solved the initial conditions, and implemented our boundary conditions, so we just use our equations from the last article, and hit GO right?

Unfortunately, the equations as-is cannot simulate binary black hole collisions, and we now enter a very murky area: Ad hoc modifying the equations, so that we can pull off these simulations correctly

In addition to the 'usual' issues, we also suffer from a unique issue: Rather low grid resolution, as well as using 32-bit floats instead of 64-bit doubles. The latter is largely a non issue luckily, but does mean that we have much less leeway for evolution errors

## What's wrong with the equations?

It took a very *very* long time for the field to be able to successfully simulate binary black hole collisions, and even longer to do full circular orbits. There are a variety of issues here, which we'll now go over

1. The gauge conditions resulted in coordinate system stretching, as well as the singularity blowing up in the moving punctures technique (well, before it was discovered)
2. Momentum constraint errors
3. Christoffel symbol constraint errors

The structure of the equations we're using are already adapted to simulating binary black holes by design, but older sets of equations were numerically unstable for these problems

### Gauge conditions

The BSSN equations contain extra degrees of freedom, and one allowance you can make is setting the non gauge variable $K=0$. This is called maximal slicing. Maximal slicing defines a coordinate system that is known (todo: paper) to have singularity avoiding tendencies, and is a good candidate from preventing our equations from exploding due to the presence of a singularity

Setting K=0 allows us to solve for the lapse via an elliptic equation derived from the <CHECKME> constraint. While elliptic equations are tricky to solve with any kind of efficiency, an approximate solution comes in the form of what is called the 1+log gauge - which is an approximate solution to the elliptic equation to drive K=0

Todo: Equation

Additionally, the shift is defined as such:

Todo: Shift

Todo: Explanation of the shift equation

$N$ is a free parameter that represents damping: In general its set to $2$, but it can also take fairly arbitrary values from $1$ to $>10$, or even vary spatially or by time. This parameter has a heavy influence on the paths of the black holes

Taken together, these two gauge conditions are called the moving puncture gauge, and are the standard choice for near equal mass binary black hole collisions

### Momentum constraint errors

These can be damped in exactly the same form as in the previous article, via:

Todo: Equation

Damping momentum constraint errors is less important for us. In an explicit integrator, high frequency oscillations due to the unstable nature of the oscillations tends to result in high frequency momentum constraint errors: Damping these improves the stability of the simulation. We run into that much less

### Christoffel symbol errors

The traditional damping scheme is as such:

Todo: Code

This is inadequate for us with our relatively low resolution, though it does improve stability

## How do we actually fix the equations?

This segment is going to be an absolute delight

# Results

Look! Black holes!


# Black holes do not really have mass

There's an unfortunate truth for black holes, which is that there is no unique definition of the mass of a black hole. Its very easy to work out how much mass there is for something like the earth - because we can calculate how much *matter* is present, but black holes here are a vacuum solution - there's no matter of any description present. This means that we have to work out what the effect on spacetime a black hole has equivalent to a certain amount of mass

There are multiple definitions of mass that we can use:

1. Bare mass, which has no physical meaning. Higher = more mass, but that's about it
2. ADM mass, which is measured at 'infinity', and measures how much energy is present in the spacetime. Only valid in asymptotically flat spacetimes
3. Komar mass - defined in stationary spacetimes
4. Horizon mass, determined by the area of the event horizon[^notruehorizon]
5. Puncture mass, determined by the size of the correction factor $\psi$ at the puncture, which approximates the ADM mass

[^notruehorizon]: If you were thinking this definition seems very straightforward, note that in a technical sense our numerical black holes don't have an event horizon. An event horizon is the 4d surface which light rays cannot escape from, but as our black holes are not eternal (and are formed by the collapse of a precursor object with no horizon), an event horizon is not present in our spacetime. If you trace a ray backwards in time, it will never become trapped in a black hole

    In the literature, a surface which is hoped to be equivalent/similar is used called the 'marginally outer trapped surface' (MOTS), which is defined locally on a specific slice. It is not the same thing as an event horizon, which can only truly be determined by tracing geodesics around in a 4-spacetime. You could also define a point in time to be approximately the 'start' of our black holes after they've formed from the precursor objects, and use that to approximate an enernal black hole (and so define a true event horizon) while tracing geodesics. I'm not aware of anyone doing this though

Black holes are a form of energy stored in spacetime and are a global phenomenon. Two black holes which are nearby each other store a significant amount of energy in the spacetime between them, increasing their mass (essentially further delocalising them). This makes it hard to pin down exactly how much 'mass' an individual black hole has in a binary pair, because they aren't truly separate phenonema. This means that all of these definitions of mass can disagree

Despite this, its very common to use ADM mass via puncture mass, and horizon mass with an approximation to its event horizon[^notruehorizon]. We'll be using the former
