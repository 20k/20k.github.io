---
layout: post
title:  "Implementing General Relativity: What's inside a black hole?"
date:   2025-05-18 00:35:23 +0000
categories: C++
---

Hello! Today we're going to do something really cool: Throw ourselves into a black hole and find out what happens. To do this, we need to upgrade our understanding of initial conditions in general relativity via tetrads, and we're also going to learn what parallel transport is

The scope of this article is as follows:

1. First we examine the role of coordinate systems in general relativity
2. Then we'll upgrade to a black hole metric which lets us cross the event horizon
3. After this, we'll learn how to calculate initial conditions for *any* metric tensor, instead of using pre-baked initial conditions
4. Then we'll learn how to follow the path that an observer takes as it moves around spacetime - and in our case, into whatever lies inside a black hole
5. There will be at least one cat photo in this article

This will all be on the GPU, so it'll run reasonably fast. We're starting to get into things that people haven't really simulated extensively, and this is an area where many simulations are incorrect

# Coordinate systems

In the first episode on rendering the schwarzschild black hole, I presented you with this:

$$ ds^2 = -d\tau^2 = -(1-\frac{r_s}{r}) dt^2 + (1-\frac{r_s}{r})^{-1} dr^2 + r^2 d\Omega^2 $$

where $d\Omega^2 = d\theta^2 + sin^2(\theta) d\phi^2$

And called it the metric tensor for a schwarzschild black hole. This was a white lie - this is, in the more technical sense, *a* representation of the schwarzschild black hole, in a particular coordinate system known as schwarzschild coordinates. Here's another representation:

$$ ds^2 = -(1-rs/r) dv^2 + 2 dvdr + r^2 d\Omega^2 $$

In eddington-finkelstein coordinates. And another:

$$ ds^2 = -d\tau^2 + rs/r dp^2 + r^2 d\Omega^2 $$

In Lema√Ætre coordinates. Note that the $d\tau$ is not proper time, its just a reuse of notation because in one specific circumstance it is proper time

The schwarzschild metric is an abstract object, which we can express in different coordinate systems. All of the above metrics describe the same fundamental object, but in different coordinates. These different coordinate systems may describe different parts of the spacetime, may have some special properties, or might be totally abstract - but there isn't a difference in what they represent

Different coordinate systems may have different properties. For example, schwarzschild coordinates - the one we used previously- has an artificial coordinate singularity at the event horizon, which makes it useless for what we're trying to do. #2 is schwarzschild in eddington-finkelstein coordinates, and is usable for describing geodesics which are travelling forwards in time into the black hole (or equivalently, geodesics that are travelling out of the black hole backwards in time). Because of the simplicity - we're going to use eddington finkelstein coordinates in the beginning

# Tetrads

Back in ye olde schwarzschild in schwarzschild coordinates days, we learnt briefly about the role of tetrads, as objects that can be used to take a local quantity, and transform into a quantity in our coordinate system (and vice versa). These objects also fundamentally relate the viewpoints of two different observers, and the first thing we need to learn is how to calculate and manipulate them. We're going to take a second crack at them now

As we've run into before: spacetime is locally flat. The technical definition of locally flat is the minkowski metric tensor $\eta_{\mu\nu}$: this is a diagonal matrix, that looks like this:

| |t|x|y|z|
|-|-|-|-|-|
|t|-1| | | |
|x| |1| | |
|y| | |1| |
|z| | | |1|

What we'd like to do, is define how to translate from our metric tensor $g_{\mu\nu}$, to our diagonal matrix $\eta_{\mu\nu}$ -we know from general relativity that the metric must be diagonalisable to produce the minkowski metric (as space is locally flat)

This is done via the standard relation:

$$D = P^{-1} A P$$

Where $D$ is our diagonal matrix, $A$ is our matrix to diagonalise, and $P$ is the diagonalising matrix. Put in our terminology[^wheresthet]

$$\eta = e^{T} g e$$

[^wheresthet]: Because the metric tensor is symmetric, the $^{-1}$ becomes a $^T$

The matrix $e$, treated as column vectors, makes up our tetrad vectors. On top of this, we can solve for $e$ and get 'a' valid set of tetrad vectors for any metric tensor, by solving this equation. Tetrads are not unique, so we're just solving for the view for some arbitrary observer, that's dependent on the specific form of the metric

Solving this is an eigenvalue problem, as $e$ also makes up the eigenvectors of the metric (and technically, $\eta_{\mu\nu}$ is the eigenvalues)

One important thing to get back to. Remember that vectors can be timelike ($ds^2 < 0$), or spacelike ($ds^2 > 0$). We have one timelike tetrad vector: which is always $e_0$, and 3 spacelike tetrad vectors, which are $e_k$

## Relativistic gram-schmidt

The most straightforward algorithm for doing this is called gram-schmidt orthonormalisation, and with a minor extension we can use this for solving our GR eigenvalue problem. Gram-schmidt is an algorithm for taking a series of vectors and making them orthonormal to each other. Here we take a series of coordinate vectors, and make them orthonormal with respect to the metric tensor from each other

We're going to start off with the basic algorithm, and then we'll make it robust against the horrors of GR

Lets start off with our 4 coordinate directions, which we hope are linearly independent:

```c++
std::array<t4f, 4> vecs = { {1, 0, 0, 0},
                            {0, 1, 0, 0},
                            {0, 0, 1, 0},
                            {0, 0, 0, 1} };
```

Note that, taking the column vectors of the metric $g_{\mu\nu}$, and raising them with the metric tensor to get $v^k$ (contravariant), produces exactly the same vectors we're starting off with here

We have to pick a vector to start our orthonormalisation from, so we pick the first vector $v_0$ arbitrarily, and now start up our algorithm:

```c++
m44f metric = get_metric();
tetrads tet = gram_schmidt(vecs[0], vecs[1], vecs[2], vecs[3], metric);
```

Relativistic gram schmidt itself looks like this:

```c++
valuef dot(t4f u, t4f v, m44f m) {
    t4f lowered = m.lower(u);

    return dot(lowered, v);
}

t4f gram_project(t4f u, t4f v, m44f m) {
    valuef top = dot_metric(u, v, m);
    valuef bottom = dot_metric(u, u, m);

    return (top / bottom) * u;
}

t4f normalise(t4f in, m44f m)
{
    valuef d = dot_metric(in, in, m);

    return in / sqrt(fabs(d));
}

struct tetrad ]
    std::array<t4f, 4> tetrvads;
}

tetrad gram_schmidt(t4f v0, t4f v1, t4f v2, t4f v3, m44f m)
{
    float4 u0 = v0;

    float4 u1 = v1;
    u1 = u1 - gram_project(u0, u1, m);

    float4 u2 = v2;
    u2 = u2 - gram_project(u0, u2, m);
    u2 = u2 - gram_project(u1, u2, m);

    float4 u3 = v3;
    u3 = u3 - gram_project(u0, u3, m);
    u3 = u3 - gram_project(u1, u3, m);
    u3 = u3 - gram_project(u2, u3, m);

    u0 = normalise(u0, m);
    u1 = normalise(u1, m);
    u2 = normalise(u2, m);
    u3 = normalise(u3, m);

    return {u0, u1, u2, u3}
};
```

We now have our tetrads. If you're confused what's going on here, so am I and I need to more rigorously revisit this portion of the article, because how I derived this is a mystery to me

### Of course, it isn't remotely that simple

There are a few assumptions that we've made here

1. That the first vector we picked doesn't have a length of 0, ie it isn't null ($ds^2 = 0$)

2. The first vector we picked is *timelike*. In general, we always demand that our first tetrad $e_0$ is a timelike vector, and there's no guarantee that $(1, 0, 0, 0)$ points in a timewards direction

### Selecting the first vector

Picking the first vector is fairly straightforward: we need to loop over our vectors, and find one who's length is not 0. Remember that in general relativity, the length of a vector is determined by

$$g_{\mu\nu} v^\mu v^nu = ds^2$$

```c++
v4f v0 = {1, 0, 0, 0};
v4f v1 = {0, 1, 0, 0};
v4f v2 = {0, 0, 1, 0};
v4f v3 = {0, 0, 0, 1};

m44f metric = GetMetric(camera_position.get());

v4f lv0 = metric.lower(v0);
v4f lv1 = metric.lower(v1);
v4f lv2 = metric.lower(v2);
v4f lv3 = metric.lower(v3);

//this declares an array gpuside, like. We end up with float4 as_array[4] = {v0, v1, v2, v3};
array_mut<v4f> as_array = declare_mut_array_e<v4f>(4, {v0, v1, v2, v3});
array_mut<valuef> lengths = declare_mut_array_e<valuef>(4, {dot(v0, lv0), dot(v1, lv1), dot(v2, lv2), dot(v3, lv3)});

mut<valuei> first_nonzero = declare_mut_e(valuei(0));

for_e(first_nonzero < 4, assign_b(first_nonzero, first_nonzero+1), [&] {
    auto approx_eq = [](const valuef& v1, const valuef& v2) {
        valuef bound = 0.0001f;

        return v1 >= v2 - bound && v1 < v2 + bound;
    };

    if_e(!approx_eq(lengths[first_nonzero], valuef(0.f)), [&] {
            break_e();
    });
});

swap(as_array[0], as_array[first_nonzero]);

tetrad tetrads = gram_schmidt(iv0, iv1, iv2, iv3, metric);
```

### Picking the timelike vector, and putting it in slot 0

We know from our diagonalisation procedure, that:

$$\eta = e^{T} g e$$

$\eta$ here isn't necessarily exactly the minkowski tensor. We're solving an eigenvalue/vector problem, and the sign of each component corresponds to whether or not each coordinate at a point is timelike, or spacelike. If we use the above relation with the tetrads we get to calculate the minkowski metric, we may instead end up with this

| |?|t|?|?|
|-|-|-|-|-|
|?|1| | | |
|t| |-1| | |
|?| | |1| |
|?| | | |1|

Or this:

| |?|?|t|?|
|-|-|-|-|-|
|?|1| | | |
|?| |1| | |
|t| | |-1| |
|?| | | |1|


Or this!

| |?|?|?|t|
|-|-|-|-|-|
|?|1| | | |
|?| |1| | |
|?| | |1| |
|t| | | |-1|


The reason why we list the coordinates as $?$'s is because while they correspond to cartesian coordinate directions, the specifics of which direction (x, y, or z) they are is inherently arbitrary[^arbitrary]

[^arbitrary]: We will be doing some tricks when we implement fps camera controls to assign some physical meaning to these directions shortly
What we would like to do is demand that the 0'th tetrad is timelike, as this is an extremely common requirement in the literature, and simplifies our lives tremendously when dealing with tetrads if we know that $e_0$ is timelike

There are two ways equivalent ways of doing this

### Way the first

Calculate the minkowski metric, and find the timelike coordinate by looking for the $-1$ component

### Way the second

Calculate $ds^2_i$ via $g_{\mu\nu} e^{\mu}_i e^{\nu}_i$, and find the component with the value of $-1$

### These are literally the same thing

We haven't seen an explicit expression for how to do this the first way whereas previous articles contain plenty of the second, so we'll pick the first

```c++
m44f get_local_minkowski(const tetrad& tetrads, const m44f& met)
{
    m44f minkowski;

    tensor<valuef, 4, 4> m;

    for(int i=0; i < 4; i++)
    {
        m[0, i] = tetrads.v[0][i];
        m[1, i] = tetrads.v[1][i];
        m[2, i] = tetrads.v[2][i];
        m[3, i] = tetrads.v[3][i];
    }

    for(int a=0; a < 4; a++)
    {
        for(int b=0; b < 4; b++)
        {
            valuef sum = 0;

            for(int mu=0; mu < 4; mu++)
            {
                for(int v=0; v < 4; v++)
                {
                    sum += met[mu, v] * m[a, mu] * m[b, v];
                }
            }

            minkowski[a, b] = sum;
        }
    }

    return minkowski;
}

//calculates the minkowski metric, and looks across the diagonal looking for the largest negative value
valuei calculate_which_coordinate_is_timelike(const tetrad& tetrads, const m44f& met)
{
    m44f minkowski = get_local_minkowski(tetrads, met);

    using namespace single_source;

    mut<valuei> lowest_index = declare_mut_e(valuei(0));
    mut<valuef> lowest_value = declare_mut_e(valuef(0));

    for(int i=0; i < 4; i++)
    {
        if_e(minkowski[i, i] < lowest_value, [&] {
            as_ref(lowest_index) = valuei(i);
            as_ref(lowest_value) = minkowski[i, i];
        });
    }

    return lowest_index;
}
```

While the tetrads we get here provide a clean signature of 1's and -1's due to being strictly orthonormalised, we may have tetrads which are derived from numerical sources - where inaccuracy will lead to them being much less nice to work with. For this reason, we look for the largest negative value[^note]

[^note]: Note, when you work with parallel transported (we'll get around to this) tetrad vectors, the signature never changes

Now finally, we use the timelike coordinate to swap the tetrad component out, and end up with our final tetrads again. The complete procedure is therefore this:

```c++
template<auto GetMetric>
void build_initial_tetrads(execution_context& ectx, literal<v4f> position,
                           buffer_mut<v4f> position_out,
                           buffer_mut<v4f> e0_out, buffer_mut<v4f> e1_out, buffer_mut<v4f> e2_out, buffer_mut<v4f> e3_out)
{
    using namespace single_source;

    as_ref(position_out[0]) = position.get();

    v4f v0 = {1, 0, 0, 0};
    v4f v1 = {0, 1, 0, 0};
    v4f v2 = {0, 0, 1, 0};
    v4f v3 = {0, 0, 0, 1};

    m44f metric = GetMetric(position.get());

    //these are actually the column vectors of the metric tensor
    v4f lv0 = metric.lower(v0);
    v4f lv1 = metric.lower(v1);
    v4f lv2 = metric.lower(v2);
    v4f lv3 = metric.lower(v3);

    array_mut<v4f> as_array = declare_mut_array_e<v4f>(4, {v0, v1, v2, v3});
    //we're in theory doing v_mu v^mu, but because only one component of v0 is nonzero, and the lower components are actually
    //the column vectors of the metric tensor, dot(v0, lv0) is actually metric[0,0], dot(v1, lv1) is metric[1,1] etc
    //this method therefore fails if the metric has no nonzero diagonal components
    array_mut<valuef> lengths = declare_mut_array_e<valuef>(4, {dot(v0, lv0), dot(v1, lv1), dot(v2, lv2), dot(v3, lv3)});

    mut<valuei> first_nonzero = declare_mut_e(valuei(0));

    for_e(first_nonzero < 4, assign_b(first_nonzero, first_nonzero+1), [&] {
        auto approx_eq = [](const valuef& v1, const valuef& v2) {
            valuef bound = 0.0001f;

            return v1 >= v2 - bound && v1 < v2 + bound;
        };

        if_e(!approx_eq(lengths[first_nonzero], valuef(0.f)), [&] {
             break_e();
        });
    });

    swap(as_array[0], as_array[first_nonzero]);

    v4f iv0 = declare_e(as_array[0]);
    v4f iv1 = declare_e(as_array[1]);
    v4f iv2 = declare_e(as_array[2]);
    v4f iv3 = declare_e(as_array[3]);

    tetrad tetrads = gram_schmidt(iv0, iv1, iv2, iv3, metric);

    array_mut<v4f> tetrad_array = declare_mut_array_e<v4f>(4, {});

    as_ref(tetrad_array[0]) = tetrads.v[0];
    as_ref(tetrad_array[1]) = tetrads.v[1];
    as_ref(tetrad_array[2]) = tetrads.v[2];
    as_ref(tetrad_array[3]) = tetrads.v[3];

    swap(tetrad_array[0], tetrad_array[first_nonzero]);

    valuei timelike_coordinate = calculate_which_coordinate_is_timelike(tetrads, metric);

    swap(tetrad_array[0], tetrad_array[timelike_coordinate]);

    as_ref(e0_out[0]) = tetrad_array[0];
    as_ref(e1_out[0]) = tetrad_array[1];
    as_ref(e2_out[0]) = tetrad_array[2];
    as_ref(e3_out[0]) = tetrad_array[3];
}
```

While it may seem odd to do this on a GPU with only one thread, this procedure is exactly the same as what we'll need in the future for working with particle systems, so we may as well GPUify this

## Following an inertial observer

So, now we have a position: our camera, and an initial tetrad: The one we calculating from the above position. The question is, how do we follow the movements of our observer in a physically accurate way? Today we're going to be dealing with strictly inertial observers that don't accelerate, and we're additionally not going to imbue our observers with any velocity - this means that they strictly will fall directly towards the black hole

The $e_0$ component of our tetrads is timelike - more than that it also represents the velocity of the observer that that tetrad is made for. That is to say, if we have

$$e_0 = (1, 0, 0, 0)$$

We are dealing with an observer who's velocity is $v^\mu = (1, 0, 0, 0)$. The first thing we need to do is to build a geodesic from our initial observers starting location, and our initial observers velocity. Lets call these $x^{\mu}$ and $v^{\mu}$

Luckily for us, the geodesic equation for lightrays, and timelike geodesics, is exactly the same, which means we do not need a new procedure to integrate our timelike geodesic. We're going to need to save[^alternate] the positions and velocities of our geodesic as we trace it, so we will need a slightly different integration scheme

[^alternate]: An alternative approach would be to step the timelike geodesics forwards as we advance forwards in proper time, but its super useful to have the whole history available to us. It also allows us to disconnect the parallel transport process, from the timelike geodesic tracing, which makes things cleaner

```c++
template<auto GetMetric>
void trace_geodesic(equation_context& ctx, buffer<v4f> start_position, buffer<v4f> start_velocity, buffer_mut<v4f> positions_out, buffer_mut<v4f> velocity_out, buffer_mut<valuei> written_steps, literal<valuei> max_steps)
{
    using namespace single_source;

    m44f metric = GetMetric(g.position);

    mut<valuei> result = declare_mut_e(valuei(0));

    mut_v4f position = declare_mut_e(start_position[0]);
    mut_v4f velocity = declare_mut_e(start_velocity[0]);

    //for a timelike geodesic, dt is proper time
    float dt = 0.005f;
    valuef start_time = start_position[0][0];
    pin(start_time);

    mut<valuei> idx = declare_mut_e("i", valuei(0));

    for_e(idx < 1024 * 1024, assign_b(idx, idx + 1), [&]
    {
        v4f cposition = declare_e(position);
        v4f cvelocity = declare_e(velocity);

        v4f acceleration = calculate_acceleration_of(cposition, cvelocity, get_metric);

        pin(acceleration);

        as_ref(velocity) = cvelocity + acceleration * dt;
        as_ref(position) = cposition + velocity.as<valuef>() * dt;

        valuef radius = position[1];

        value<bool> is_broken = !isfinite(position[0]) || !isfinite(position[1]) || !isfinite(position[2]) || !isfinite(position[3]) ||
                                !isfinite(velocity[0]) || !isfinite(velocity[1]) || !isfinite(velocity[2]) || !isfinite(velocity[3]) ;

        if_e(radius > 10 || position[0] > start_time + 1000 || fabs(velocity[0]) >= 10 || is_broken, [&] {
            break_e();
        });

        as_ref(positions_out[idx]) = position;
        as_ref(velocities_out[idx]) = velocity;
    });

    as_ref(written_steps[0]) = idx.as_constant();
}
```

This procedure is very similar to our regular raytracing, but we're writing all the positions and velocities out to a buffer. The termination condition is different now as well, we're guessing that when the velocity of a geodesic becomes very high, we're approaching a singularity[^rsmall]. This modification must also be applied to our light rays for them to correctly terminate

[^rsmall]: We could use `r < 0.000001f` or similar, but this will not work for where we're going with kerr

We've now traced through the history of a timelike geodesic, and saved the positions and velocities so that we can examine the path that our observer takes through our spacetime. What we'd like to do now, is at a specific point along this timelike geodesic representing our observer, find out what that observer would see. The way to do this, is by parallel transporting the tetrads, and use them as a basis for our observer

## Parallel Transport

The way that parallel transport works is as following: If you imagine a geodesic as a curve, and take a vector tangent to that curve, that vector remains tangent to the curve at every point along it. A vector which does this is said to be "parallel transported". This is true for every vector - you can imagine the geodesic equation as the process of parallel transporting the velocity vector itself along the geodesic - this is in fact one definition of a geodesic (autoparallel transport)

Todo: Picture of parallel transport

To parallel transport something is when the *covariant* derivative of a vector vanishes along a curve. We haven't gotten around to covariant derivatives yet, but they're the general relativistic coordinate free generalisation of partial derivatives. For more information, see [this](https://physics.stackexchange.com/questions/524242/parallel-transport-of-a-vector) link, and [here](https://en.wikipedia.org/wiki/Covariant_derivative#Covariant_derivative_by_field_type) for how to calculate covariant derivatives

For us, given a timelike geodesic parameterised by proper time, with a position $x^{\mu}$ and velocity $v^\mu = \frac{dx}{d\tau}$, the parallel transport equation for a vector $A^\mu$ is this:

$$\frac{dA^\alpha}{d\tau} = -v^\sigma \Gamma^\alpha_{\;\;\beta\sigma} A^\beta$$

In code:

```c++
v4f parallel_transport_get_change(v4f tangent_vector, v4f geodesic_velocity, const tensor<valuef, 4, 4, 4>& christoff2)
{
    v4f dAdt = {};

    for(int a=0; a < 4; a++)
    {
        float sum = 0;

        for(int b=0; b < 4; b++)
        {
            for(int s=0; s < 4; s++)
            {
                sum += christoffel[a,b,s] * tangent_vector[b] * geodesic_velocity[s];
            }
        }

        dAdt[a] = -sum;
    }

    return dAdt;
}
```

At this point, we just need to integrate this along our curve, and produce our parallel transported tetrads. We're going to build another kernel for this:

```c++
//note: we already know the value of e0, as its the geodesic velocity
template<auto GetMetric>
void parallel_transport_tetrads(buffer<v4f> e1, buffer<v4f> e2, buffer<v4f> e3, buffer<v4f> positions, buffer<v4f> velocities, buffer<valuei> counts,
buffer_mut<v4f> e1_out, buffer_mut<v4f> e2_out, buffer_mut<v4f> e3_out)
{
    //its important that this dt is the same dt as the one that we used in trace_geodesic, as we're dealing with the same parameterisation. If you use a variable timestep, you need to write this into a buffer
    float dt = 0.005f;

    valuei count = declare_e(counts[0].get());
    valuei i = declare_mut_e(valuei(0));

    buffer_mut<v4f> e1_current = declare_mut_e(e1[0]);
    buffer_mut<v4f> e2_current = declare_mut_e(e2[0]);
    buffer_mut<v4f> e3_current = declare_mut_e(e3[0]);

    for_e(i < count, assign_b(i, i+1), [&] {
        as_ref(e1_out[i]) = e1_current;
        as_ref(e2_out[i]) = e2_current;
        as_ref(e3_out[i]) = e3_current;

        v4f current_position = positions[i];
        v4f current_velocity = velocities[i];

        tensor<valuef, 4, 4, 4> christoff2 = calculate_christoff2(current_position, GetMetric);

        pin(christoff2);

        v4f e1_cst = declare_e(e1_current);
        v4f e2_cst = declare_e(e2_current);
        v4f e3_cst = declare_e(e3_current);

        v4f e1_change = parallel_transport_get_change(e1_cst, current_velocity, christoff2);
        v4f e2_change = parallel_transport_get_change(e2_cst, current_velocity, christoff2);
        v4f e3_change = parallel_transport_get_change(e3_cst, current_velocity, christoff2);

        as_ref(e1_current) = e1_current + e1_change * dt;
        as_ref(e2_current) = e2_current + e2_change * dt;
        as_ref(e3_current) = e3_current + e3_change * dt;
    });

    if_e(count == 0, []{
        break_e();
    });

    as_ref(e1_out[count-1]) = e1_current;
    as_ref(e2_out[count-1]) = e2_current;
    as_ref(e3_out[count-1]) = e3_current;
}
```

Phew. This is a pretty simple 1st order integrator that parallel transports the $e_{1,2,3}$ components of our tetrad, and writes them out to a buffer

## Interpolation

The very last thing for us to do now, is to actually construct our initial conditions. If you remember, we need a position, and a set of tetrads, and that's it for starting up our raytracing. We now have a buffer of positions, and a buffer of parallel transported tetrads - and that's all we're going to need to produce our starting point

```c++
void interpolate(buffer<v4f> positions, buffer<v4f> e0s, buffer<v4f> e1s, buffer<v4f> e2s, buffer<v4f> e3s, buffer<valuei> counts,
literal<valuef> desired_proper_time,
buffer_mut<v4f> position_out, buffer_mut<v4f> e0_out, buffer_mut<v4f> e1_out, buffer_mut<v4f> e2_out, buffer_mut<v4f> e3_out)
{
    //it is again important that this timestep matches the one from parallel transported tetrads
    float dt = 0.005f;

    valuei i = declare_mut_e(valuei(0));

    mut<valuef> elapsed_time = declare_mut_e(valuef(0));

    //fallback if we pick proper time < earliest time
    as_ref(position_out[0]) = positions[0];
    as_ref(e0_out[0]) = e0s[0];
    as_ref(e1_out[0]) = e1s[0];
    as_ref(e2_out[0]) = e2s[0];
    as_ref(e3_out[0]) = e3s[0];

    valuei size = declare_e(counts[0]);

    if_e(size == 0, [&] {
        return_e();
    });

    for_e(i < size, assign_b(i, i+1), [&] {
        if_e(elapsed_time >= desired_proper_time.get() && elapsed_time <= desired_proper_time.get() + dt, [&]{
            valuef frac = (elapsed_time - desired_proper_time) / dt;

            as_ref(position_out[0]) = mix(positions[i], positions[i+1], frac);
            as_ref(e0_out[0]) = mix(e0s[i], e0s[i+1], frac);
            as_ref(e1_out[0]) = mix(e1s[i], e1s[i+1], frac);
            as_ref(e2_out[0]) = mix(e2s[i], e2s[i+1], frac);
            as_ref(e3_out[0]) = mix(e3s[i], e3s[i+1], frac);

            return_e();
        });

        as_ref(elapsed_time) = elapsed_time + dt;
    });

    //fallback for if we pick proper time > latest proper time
    as_ref(position_out[0]) = positions[0];
    as_ref(e0_out[0]) = e0s[size-1];
    as_ref(e1_out[0]) = e1s[size-1];
    as_ref(e2_out[0]) = e2s[size-1];
    as_ref(e3_out[0]) = e3s[size-1];
}
```

This searches for the correct proper time, and interpolates our tetrads and starting position based on whatever proper time we're looking for. Its worth noting that with our timestep being linear, we could do this a lot more directly, but you're likely going to have a dynamic timestep

# Reviewing the complete procedure

1. Calculate your tetrads at any point
2. Ensure that $e_0$ is timelike
3. Trace the timelike $e_0$ forwards, as it represents our observer
4. Parallel transport the other vectors $e_1$ $e_2$ $e_3$ forwards along the geodesic that we define in step 3.
5. Calculate our final tetrad and position, by interpolating along that geodesic
6. Raytrace using that tetrad and position[^kernel] as our initial conditions, in the usual fashion

[^kernel]: For this article, we've changed the kernel we use to take a tetrad from a buffer

# Results

First up, lets examine some results for schwarzschild. We know that the event horizon in schwarzschild is not traversible, and so any observer attempting to cross the event horizon will hit a coordinate singularity. This isn't a real singularity, but its worth examining

