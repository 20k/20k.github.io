---
layout: post
title:  "Numerical Relativity 103: Raytracing numerical spacetimes"
date:   2026-01-12 12:33:23 +0000
categories: C++
---

Hi! Today we're going to look at raytracing geodesics in numerical spacetimes. We're going to explore two things:

1. The ADM geodesic equations to produce a fast approximate rendering, mainly for debugging reasons
3. The regular geodesic equation to accurately raytrace inspiralling binary black holes

Along the way, I'll present to you a modified form of the verlet algorithm which is the best bang for your buck that you can get.

Video:

I'd highly recommend reading todo: this article about geodesics in general relativity, but we'll have a recap before we get started

# What are we trying to do?

scrap 99% of this, and just use a 4d argument

Today, we're going to raytrace light rays around our spacetime, and produce a rendering of it. If you're familiar with raytracing in general, you might imagine a raytracer which fires rays through a 3d grid

In 3d, a ray has two properties: a position, and a velocity, both 3-vectors. Adding an acceleration to your rays is straightforwardly modelled as an acceleration, applied at each step as you step along a ray in the 3rd volume

Stretching this into 4d is straightforward. Instead of a 3d grid, we now have a 4d grid. And instead of position and velocity being 3-vectors, they now both have a 4th component attached, which allows us to represent space*time*. There's no longer a newtonian acceleration at each point in space, but a general relativistic 'acceleration'[^reallycoordinates] at each point in spacetime, dictated by the geodesic equation

One of the major differences when adding a time dimension is that light rays (cast from the camera) travel backwards in time. This is because they *finish* at the camera, so we want to work out where they originated from earlier

[^reallycoordinates]: It isn't a true acceleration in the physical sense, but represents the coordinate change of the light ray as it moves about

## A grid in 4d

not super happy on this segment, or the above

In previous articles on raytracing, we've had an analytic metric tensor $g_{\mu\nu}$, which is a 4d object. We need this to calculate our acceleration. In these simulations so far, we've had a numerical grid which is a single 3d slice, that represents the metric of some slice of spacetime defined as 'now'. Unfortunately, as our light rays travel backwards in time, we need access to earlier slices, which means storing our entire simulation history

This is a problem. We're going to discuss two different approaches here:

1. A debugging view by keeping our rays inaccurately to a single slice
2. An accurate view, where we store the entire simulation history in a reduced form

# Recap

## What are geodesics?

In general relativity, geodesics represent paths through spacetime. There are three kinds of geodesics:

1. Timelike, representing the paths of observers and massive particles
2. Null, representing the paths of massless particles like light
3. Spacelike, representing distances that cannot be traversed causally

In general, we're only interested in timelike and null geodesics. Everything in this article is applicable to both of these kinds of geodesics - though we're not going to simulate timelike geodesics today

Geodesics have two properties:

1. A 4-position, which we'll notate as $x^\mu$
2. A 4-velocity, which we'll notate as $\frac{dx^\mu}{d\lambda}$. Note that this velocity is the derivative of the position $x^\mu$ with respect to either an affine parameter $d\lambda$ (sometimes called $ds$), or coordinate time $t$. We'll be exclusively sticking with the former, to avoid confusion

As always, greek indices run from $0-4$, and latin indices run from $1-4$

## The geodesic equation

To calculate the path of a geodesic through spacetime, we can integrate the geodesic equation:

$$\frac{d^2 x^\mu}{d\lambda^2} =-\Gamma^\mu_{\alpha \beta} \frac{dx^\alpha}{d\lambda} \frac{dx^\beta}{d\lambda}$$

This gives an acceleration. $\Gamma^\mu_{\alpha \beta}$ is the christoffel symbols of the second kind. For us, the important part is that its built from the metric tensor, and its derivatives

## Recap: The ADM formalism

The ADM formalism is the process of taking a 4-metric $g_{\mu\nu}$, and splitting it up into a series of 3d slices (called a foliation). Each 3d slice has the following variables associated with it:

| Symbol | Name | Relation to normal GR  | Description |
|-|-|-|-|
| $\gamma_{ij}$ | The 3-metric tensor | $g_{ij}$ | Describes curvature on the 3 surface. Symmetric |
| $K_{ij}$ | Extrinsic curvature | $\frac{1}{2 \alpha} (D_i \beta_j + D_j \beta_i - \frac{\partial g_{ij}}{\partial_t})$ | The curvature of the 3 surface with respect to the 4th dimension. Symmetric |
| $\alpha$ | Lapse | $\sqrt{-g_{00} + \beta^m \beta_m}$ | Part of the hypersurface normal, which points into the future |
| $\beta^i$ | Shift | $g_{0i}$ | The other part of the hypersurface normal, which points into the future |

The only general relativity you need to know for this article is:

1. Raising and lowering indices
2. How to calculate a covariant derivative. $D$ is the covariant derivative associated with $\gamma_{ij}$
3. Tensor index notation

Unlike previous articles, we'll be barely dealing with the BSSN formalism at all. I'll be mentioning it in passing, but we'll use it solely to construct our relevant ADM quantities.

# The ADM geodesic equation

Today we're primarily going to be dealing with the paper [3+1 geodesic equation and images in numerical
spacetimes](https://arxiv.org/pdf/1208.3927), and discussing some of the implications. Lets get into it

## Initial conditions

The way we set up initial conditions is exactly as described in <this> article, with no changes. The sole difference is that we build the metric tensor $g_{\mu\nu}$ from the ADM components ($\gamma_{ij},\; \alpha,\; \beta^i$), rather than having a metric analytically. You'll want to implement trilinear interpolation on the fields, if your camera lives on a non integer coordinate

Because there's nothing special here, lets assume that we have a geodesic (either null, or massive), with a position $x^\mu$ and a velocity $dx^\mu$

So first up, this paper requires us to calculate the 4-momentum of our geodesic, $p^\mu$. For a timelike geodesic, the 4-momentum is defined as such[^lambda]:

$$p^\mu = m \frac{dx^\mu}{d\tau}$$

[^lambda]: For timelike geodesics, generally we set $\lambda = \tau$, ie we parameterise our geodesic by proper time

Where $m$ is the rest mass, and we've set $d\lambda = d\tau$ (the proper time). For a null geodesic, the 4-momentum is equivalent to rescaling the 4-velocity, which has [no effect](https://physics.stackexchange.com/questions/350556/definition-of-p-mu-for-a-photon-in-general-relativity) on the path (as rescaling a null geodesic is equivalent to a change in the affine parameter). Therefore we set:

$$p^\mu = \frac{dx^\mu}{d\lambda}$$

Next up, we want to find the 3-quantity on our local slice which is the projection of our 4-velocity - ie we're translating from GR to ADM. To do this, simply apply (8), and solve for $V^\mu$:

$$V^\mu = \frac{p^\mu}{E} - \mathcal{n}^\mu$$

Where

1. $E = -p_\mu \mathcal{n}^\mu$
2. $\mathcal{n}^\mu = (\frac{1}{\alpha}, -\frac{\beta^0}{\alpha}, -\frac{\beta^1}{\alpha}, -\frac{\beta^2}{\alpha})$

In practice the quantity $E = -p^\mu \mathcal{n}_{\mu}$ is easier to calculate, as we can calculate $\mathcal{n}_{\mu} =  (-\alpha, 0, 0, 0)$ directly, and we already have $p^\mu$.

$V^\mu$ is the ray velocity which is tangent to our 3-surface, and has no component in the timelike direction (ie $\mathcal{n}_\mu V^\mu = 0$). This means that $V^0 = 0$. For null geodesics, $V_i V^i = 1$, and for timelike geodesics, $V_i V^i < 1$

So, for tracing a geodesic in the ADM formalism, we have two things

1. A 4-position, which we've called $x^\mu$, and this paper calls $X^\mu$
2. A 3-velocity $V^i$, which is the projection our 4-velocity onto our local hypersurface

The 3-position of our ray's 4-position $x^\mu$ is trivially $x^i$

### A slight wrinkle: Photons going backwards in time

Its very common in these simulations to raytrace light rays backwards in time. If you're doing this (which we are), you'll note that we have no component in the timelike direction for $V^i$. The slightly odd thing to realise is that your timestep becomes *negative* when performing your raytracing, as we're quite literally doing negative steps through coordinate time

## Evolution equations

The evolution equations for our system are given by (28a) and (28b):

$$\begin{align}
\frac{dX^i}{dt} &= \alpha V^i - \beta ^i \\
\frac{dV^i}{dt} &= \alpha V^j (V^i (\partial_j \ln(\alpha) - K_{ij} V^k) + 2 K^i_j - ^3\Gamma^i_{jk} V^k) \\&- \gamma^{ij} \partial_j \alpha - V^j \partial_j \beta^i \\
\end{align}$$

Where $^3 \Gamma^i_{jk}$ are the christoffel symbols associated with $\gamma_{ij}$. I've also converted this papers notation to ours, ie $\alpha = N$

The only modifications we'll make are as follows:

1. We can replace the $\partial_j \ln(\alpha)$ term with $\frac{\partial_j \alpha}{\alpha}$, which is easier to calculate
2. For null geodesics, you can enforce $V_i V^i = 1$ by rescaling the length to improve accuracy, after each time step
3. We can calculate the christoffel symbols from the BSSN variables directly, eg see [(A3)](https://arxiv.org/pdf/1202.1038)

Note that unlike with regular geodesics, $V^i$ is *not* the velocity of $X^i$, which will complicate our lives

# Implementation on a single slice

With the evolution equations in hand, we'll want to get to implementing. We're going to be using this just to produce a debug visualisation on a single slice. The reason why we won't be using this for our accurate raytracing, is that its much less memory efficient - which is something that will become apparently when we get there

The first thing we need before we get started, is to pick an integrator

## Verlet

Euler integration is not very good for these problems, even if it does tend to be the default integrator for many problems. It has poor performance for its accuracy, and additionally it isn't symplectic. This means that a rays energy tends to diverge, and its not a great choice in general

From a lot of experience, I can tell you that Verlet integration is by far the best choice here. First off, I'm going to present the basic Verlet algorithm for this problem, and then we'll tweak it to improve performance

### Verlet for non separable hamiltonians

Wikipedia lists a form of the velocity Verlet algorithm which isn't super helpful to us. Unfortunately, we have two problems

1. Our velocity $v$ is not directly the velocity of $x$
2. Our acceleration is a function of the position *and* velocity

These are both really the same problem: what we have is what is known as a non separable hamiltonian. This means our equations are of the form:

$$\begin{align}
\dot{q} &= g(q, v)\\
\dot{v} &= f(q, v)
\end{align}$$

We need a slightly more general form of Verlet integration to combat this. We're instead going to implement (1.24) from [this](https://www.math.kit.edu/ianm3/lehre/geonumint2009s/media/gni_by_stoermer-verlet.pdf) paper, which lists the more general form of velocity Verlet integration - which is applicable to our problem

The choice of which function is $g$ or $f$ determines which variable is $q$ or $v$. In our case, we'll pick the following convention:

1. $g(q, v) = dX(x(t), v(t))$
2. $f(q, v) = dV(x(t), v(t))$

Ie, $q$ is our position $X^i$, $v$ is our velocity $V^i$, $g$ is $dX$, and $f$ is $dV$. We could reverse this, and end up with an equivalent integrator. This gives us the following integration scheme:

$$\begin{align}
V_{n+\frac{1}{2}} &= V_n + \frac{h}{2}dV(X_n, V_{n+\frac{1}{2}})\\
X_{n+1} &= X_n + \frac{h}{2}(dX(X_n, V_{n+\frac{1}{2}}) + dX(X_{n+1}, V_{n+\frac{1}{2}}))\\
V_{n+1} &= V_{n+\frac{1}{2}} + \frac{h}{2} dV(X_{n+1}, V_{n+\frac{1}{2}})\\
\end{align}$$

Where $h$ is the timestep, and $n$ is the iteration variable. You might notice that these equations are implicit. Solving these equations efficiently might seem prohibitely expensive right off the bat, especially compared to just lowering the timestep with a simple Euler scheme - luckily the problem we're trying to solve allows us to make some simplifications:

1. $dV(X, V)$ is expensive to evaluate for different values of $X$, but cheap to evaluate for different values of $V$
2. $dV(X, V)$ is only weakly dependent on the value of $V$, ie $dV(X, V + \epsilon) \approx dV(X, V)$
3. $dX(X, V)$ is cheap to evaluate
4. The underlying problem is not numerically unstable, and is very well conditioned

So, lets do some approximating and rewrite these equations in an explicit form:

$$\begin{align}
V_{n+\frac{1}{2}} &= V_n + \frac{h}{2}dV(X_n, V_n)\\
\bar{X}_{n+1} &= X_n + h \; dX(X_n, V_n)\\
X_{n+1} &= X_n + \frac{h}{2}(dX(X_n, V_{n+\frac{1}{2}}) + dX(\bar{X}_{n+1}, V_{n+\frac{1}{2}}))\\
V_{n+1} &= V_{n+\frac{1}{2}} + \frac{h}{2} dV(X_{n+1}, V_{n+\frac{1}{2}})\\
\end{align}$$

While in theory this reduces the stability and accuracy, in practice due to the nature of the problem we're trying to solve, this works extremely well[^vsolve]

[^vsolve]: Its worth noting that due to the cheapness of re-evaluating $dV$ with different values of $V$, you could solve the first equation via fixed point iteration - but due to the relatively weak dependence of the solution on pertubations in $V$, it provides relatively minimal benefits. Particularly, because we're able to *enforce* the constraint $V_i V^i = 1$ for lightlike geodesics, we are less exposed to numerical errors

The last thing we need to do is solve the double evaluation of $dV$ - we can straightforwardly rework these equations to only evaluate dV once per iteration. To do this, we'll split this up into two phases: initialisation, and then our iteration step. I'll also be relabling $h$ as $h_n$, as our timestep is dynamic:

Initialisation:

$$\begin{align}
V_{\frac{1}{2}} &= V_0 + \frac{h_0}{2}dV(X_0, V_0)\\
\bar{X}_{1} &= X_0 + h_0 \; dX(X_0, V_0)\\
X_{1} &= X_0 + \frac{h_0}{2}(dX(X_0, V_{0+\frac{1}{2}}) + dX(\bar{X}_{1}, V_{\frac{1}{2}}))\\
\end{align}$$

Iteration, starting at $n=1$:

$$\begin{align}
V_{n} &= V_{n-\frac{1}{2}} + \frac{h_{n-1}}{2} dV(X_{n}, V_{n-\frac{1}{2}})\\
V_{n+\frac{1}{2}} &= V_n + \frac{h_n}{2}dV(X_n, V_n)\\
\bar{X}_{n+1} &= X_n + h_n \; dX(X_n, V_n)\\
X_{n+1} &= X_n + \frac{h_n}{2}(dX(X_n, V_{n+\frac{1}{2}}) + dX(\bar{X}_{n+1}, V_{n+\frac{1}{2}}))\\
\end{align}$$

We now only evaluate $dV$ for the same $X_n$ within an iteration, which is roughly a 2x performance speedup. One oddity here is that our velocity iteration variable becomes $V_{n+\frac{1}{2}}$, and you do not need to store $V_n$. You also need to store $h_n$ as a variable as well, as its value is carried across loops

## Implementating Verlet

We're going to be using this verlet integrator for both the ADM equations, *and* the regular geodesic equation, as it works for both. Because of this, I'll present to you the generic form:

```c++
template<typename T, int N>
struct verlet_context
{
    tensor<mut<T>, N> position;
    mut<T> ds_m;
    tensor<mut<T>, N> last_v_half;
    tensor<mut<T>, N> velocity;

    template<typename dX, typename dV, typename dS, typename State>
    void start(const tensor<T, N>& X_in, const tensor<T, N>& V_in, dX&& get_dX, dV&& get_dV, dS&& get_dS, State&& get_state)
    {
        using namespace single_source;

        position = declare_mut_e(X_in);
        velocity = declare_mut_e(V_in);

        auto x_0 = declare_e(X_in);
        auto v_0 = declare_e(V_in);

        auto st = get_state(x_0);

        auto acceleration = get_dV(x_0, v_0, st);
        pin(acceleration);

        auto ds = get_dS(x_0, v_0, acceleration, st);
        pin(ds);

        auto v_half = v_0 + 0.5f * ds * get_dV(x_0, v_0, st);

        auto x_full_approx = x_0 + ds * get_dX(x_0, v_0, st);
        auto st_full_approx = get_state(x_full_approx);

        auto x_full = x_0 + 0.5f * ds * (get_dX(x_0, v_half, st) + get_dX(x_full_approx, v_half, st_full_approx));

        last_v_half = declare_mut_e(v_half);
        ds_m = declare_mut_e(ds);
        as_ref(position) = x_full;
    }

    template<typename dX, typename dV, typename dS, typename State>
    auto next(dX&& get_dX, dV&& get_dV, dS&& get_dS, State&& get_state, auto&& enforce_velocity_constraint)
    {
        using namespace single_source;

        auto x_n = declare_e(position);
        auto v_nhalf = declare_e(last_v_half);
        auto ds_n1 = declare_e(ds_m);

        auto st = get_state(x_n);

        auto v_n = v_nhalf + 0.5f * ds_n1 * get_dV(x_n, v_nhalf, st);

        v_n = enforce_velocity_constraint(v_n, st);
        pin(v_n);

        auto acceleration = get_dV(x_n, v_n, st);
        pin(acceleration);

        auto ds = get_dS(x_n, v_n, acceleration, st);
        pin(ds);

        auto v_half = v_n + 0.5f * ds * get_dV(x_n, v_n, st);

        auto x_full_approx = x_n + ds * get_dX(x_n, v_n, st);
        auto st_full_approx = get_state(x_full_approx);

        auto x_full = x_n + 0.5f * ds * (get_dX(x_n, v_half, st) + get_dX(x_full_approx, v_half, st_full_approx));

        as_ref(position) = x_full;
        as_ref(last_v_half) = v_half;
        as_ref(ds_m) = ds;
        //I only update this for rasterisation reasons
        as_ref(velocity) = v_half;

        //this is returned so we can use it for termination conditions
        return get_dX(x_n, v_half, st);
    }
};
```

Here, the timestep is called $ds$, and is assumed to be some function of position, velocity, and acceleration (we'll get around to timestepping very shortly). We also carry a state around, which is used to avoid reevaluating the same expression repeatedly

With all of this together, Verlet is about 3-5x better than Euler in terms of step size, for a similar cost of evaluating the equations - as we only evaluate the expensive part of $dV$ once per iteration. It does come with a register and compute penalty, but its worth the tradeoff

## Implementing ADM

### Initialisation

The setup in this segment is straightforward. The only thing that we do differently in this article is construct the 4-metric from the bssn variables. See todo: this article for more details

This is the full routine that I use for the metric $g_{\mu\nu}$ calculation:

```c++
auto get_metric = [](v4f position, bssn_args_mem<buffer<valuef>> in, literal<v3i> dim, literal<valuef> scale)
{
    using namespace single_source;

    v3f grid = world_to_grid(position.yzw(), dim.get(), scale.get());

    //our boundary is at {1,1,1}, and we need room for trilinear interpolation to touch adjacent cells
    grid = clamp(grid, (v3f){2,2,2}, (v3f)dim.get() - (v3f){3,3,3});

    pin(grid);

    adm_variables adm = admf_at(grid, dim.get(), in);

    auto met = calculate_real_metric(adm.Yij, adm.gA, adm.gB);
    pin(met);
    return met;
};
```

Where 4-metric can be calculated from the ADM variables as follows:

```c++
metric<valuef, 4, 4> calculate_real_metric(const metric<valuef, 3, 3>& adm, const valuef& gA, const tensor<valuef, 3>& gB)
{
    tensor<valuef, 3> gB_lower = lower_index(gB, adm, 0);

    metric<valuef, 4, 4> ret;

    valuef gB_sum = sum_multiply(gB_lower, gB);

    ///https://arxiv.org/pdf/gr-qc/0703035.pdf 4.43
    ret[0, 0] = -gA * gA + gB_sum;

    ///latin indices really run from 1-4
    for(int i=1; i < 4; i++)
    {
        ///https://arxiv.org/pdf/gr-qc/0703035.pdf 4.45
        ret[i, 0] = gB_lower[i - 1];
        ret[0, i] = ret[i, 0]; ///symmetry
    }

    for(int i=1; i < 4; i++)
    {
        for(int j=1; j < 4; j++)
        {
            ret[i, j] = adm[i-1, j-1];
        }
    }

    return ret;
}
```

And here I construct the ADM variables from the interpolated BSSN variables, via a standard trilinear interpolation:

```c++
adm_variables admf_at(v3f pos, v3i dim, bssn_args_mem<buffer<valuef>> in)
{
    using namespace single_source;

    adm_variables out;

    auto cY_at = [&](v3i pos) {
        return bssn_at(pos, dim, in).cY;
    };

    auto W_at = [&](v3i pos) {
        return bssn_at(pos, dim, in).W;
    };

    auto cA_at = [&](v3i pos) {
        return bssn_at(pos, dim, in).cA;
    };

    auto K_at = [&](v3i pos) {
        return bssn_at(pos, dim, in).K;
    };

    auto gA_at = [&](v3i pos) {
        return bssn_at(pos, dim, in).gA;
    };

    auto gB_at = [&](v3i pos) {
        return bssn_at(pos, dim, in).gB;
    };

    auto cY = function_trilinear(cY_at, pos);
    auto cA = function_trilinear(cA_at, pos);
    auto W = function_trilinear(W_at, pos);
    auto K = function_trilinear(K_at, pos);
    auto gA = function_trilinear(gA_at, pos);
    auto gB = function_trilinear(gB_at, pos);

    out.Yij.from_tensor(cY.to_tensor() / (W*W));
    out.Kij = (cA + cY.to_tensor() * (K/3.f)) / (W*W);
    out.gA = gA;
    out.gB = gB;

    pin(out.Yij);
    pin(out.Kij);
    pin(out.gA);
    pin(out.gB);

    return out;
}
```

### Raytracing

The basic form of our raytracing scheme is as follows:

```c++

void trace3(execution_context& ectx, literal<v2i> screen_sizel,
            literal<v4f> camera_quat,
            buffer_mut<v4f> positions, buffer_mut<v4f> velocities,
            buffer_mut<valuei> results, buffer_mut<valuef> zshift,
            literal<v3i> dim,
            literal<valuef> scale,
            bssn_args_mem<buffer<valuef>> in,
            bssn_derivatives_mem<buffer<derivative_t>> derivatives)
{
    using namespace single_source;

    valuei x = value_impl::get_global_id(0);
    valuei y = value_impl::get_global_id(1);

    //get_global_id() is not a const function, so assign it to an unnamed variable to avoid compilers repeatedly evaluating it
    pin(x);
    pin(y);

    v2i screen_size = screen_sizel.get();

    if_e(y >= screen_size.y(), [&] {
        return_e();
    });

    if_e(x >= screen_size.x(), [&] {
        return_e();
    });

    v2i screen_position = {x, y};

    v3f pos_in = declare_e(positions[screen_position, screen_size]).yzw();
    v3f vel_in = declare_e(velocities[screen_position, screen_size]).yzw();

    mut<valuei> result = declare_mut_e(valuei(2));

    <Todo: DEFINE get_dX, get_dV, get_dS, get_state here!>

    verlet_context<valuef, 3> ctx;
    ctx.start(pos_in, vel_in, get_dX, get_dV, get_dS, get_state);

    mut<valuei> idx = declare_mut_e("i", valuei(0));

    for_e(idx < 512, assign_b(idx, idx + 1), [&]
    {
        v3f cposition = declare_e(ctx.position);
        v3f cvelocity = declare_e(ctx.velocity);

        valuef radius_sq = dot(cposition, cposition);

        //terminate if we're out of the sim
        if_e(radius_sq > UNIVERSE_SIZE*UNIVERSE_SIZE, [&] {
            as_ref(result) = valuei(1);
            break_e();
        });

        //terminate if our rays become non finite
        if_e(!isfinite(cvelocity.x()) || !isfinite(cvelocity.y()) || !isfinite(cvelocity.z()), [&]{
            as_ref(result) = valuei(0);
            break_e();
        });

        v3f diff = ctx.next(get_dX, get_dV, get_dS, get_state, fix_velocity);

        //terminate if the movement of our ray through coordinate space becomes trapped, its likely hit an event horizon
        if_e(diff.squared_length() < 0.1f * 0.1f, [&]
        {
            as_ref(result) = valuei(0);
            break_e();
        });
    });

    v3f final_position = declare_e(ctx.position);
    v3f final_velocity = declare_e(ctx.velocity);

    as_ref(positions[screen_position, screen_size]) = (v4f){0, final_position.x(), final_position.y(), final_position.z()};
    as_ref(velocities[screen_position, screen_size]) = (v4f){0, final_velocity.x(), final_velocity.y(), final_velocity.z()};
    as_ref(results[screen_position, screen_size]) = as_constant(result);
}
```

show loop structure

# Accurate rendering

geodesic equation wooooooooooo i'm too tired for this

# Results

# Discussion

## Why not timelike geodesics?

While the ADM equations of motion presented in this article are applicable to timelike geodesics, in practice integrating them into a simulation is radically different than what you'd do for lightlike geodesics. Its sufficiently different that - beyond the specific equations themselves - there's little commonality in terms of implementation. We'll be doing timelike geodesics when we hit N-body particle dynamics - likely in a few articles time

# Addendum (texture filtering?)